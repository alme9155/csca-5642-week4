{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ac4925",
   "metadata": {
    "papermill": {
     "duration": 0.003506,
     "end_time": "2025-07-18T23:58:11.705988",
     "exception": false,
     "start_time": "2025-07-18T23:58:11.702482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSCA-5642: Diaster Tweets Classification Analysis Project #\n",
    "#### Develop an algorithm to predict which Tweets are about real disasters and which ones are not. ####\n",
    "    \n",
    "* Author: Alexander Meau  \n",
    "* Email: alme9155@colorado.edu  \n",
    "* GitHub: [https://github.com/alme9155/csca-5642-week4/tree/main](https://github.com/alme9155/csca-5642-week4/tree/main)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa020c4",
   "metadata": {
    "papermill": {
     "duration": 0.002502,
     "end_time": "2025-07-18T23:58:11.711679",
     "exception": false,
     "start_time": "2025-07-18T23:58:11.709177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## I. Brief description of the problem and data ##\n",
    "\n",
    "This project aims to tackle the Natural diaster tweet prediction to run a binary text classification whether a tweet refers to a real disaster event or not.\n",
    "### Dataset: ####\n",
    "* The competition dataset contains 3 CSV files: \"train.csv\", \"test.csv\" and \"sample_submission.csv\".\n",
    "* File \"train.csv\" contains development data with target label (target=1) or not (target=0).\n",
    "* File \"test.csv\" contains test data to be classified for the competition.\n",
    "* File \"sample_submission.csv\" contains sample submission format after text classification prediction.\n",
    "\n",
    "### Data Size and Dimension ####\n",
    "* Training dataset: ~7000 tweet text \n",
    "* Test dataset: 57,458 tiff images (~26% of training size)\n",
    "* Each image patch is 96x96 pixel of RGB color images in tiff formats.\n",
    "* Label CSV contains 2 columns: id, label (1 as cancerous, 0 as non-cancerous)\n",
    "\n",
    "### Competition Rules ###\n",
    "* Expected submission CSV files in the same format as \"train_labels.csv\" with two columns \"id, label\". (id: unique id from test set, label: 0, or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3354becb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:11.718648Z",
     "iopub.status.busy": "2025-07-18T23:58:11.718239Z",
     "iopub.status.idle": "2025-07-18T23:58:13.611249Z",
     "shell.execute_reply": "2025-07-18T23:58:13.610127Z"
    },
    "papermill": {
     "duration": 1.898522,
     "end_time": "2025-07-18T23:58:13.612907",
     "exception": false,
     "start_time": "2025-07-18T23:58:11.714385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6eb043",
   "metadata": {
    "papermill": {
     "duration": 0.003003,
     "end_time": "2025-07-18T23:58:13.619171",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.616168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Brief description of the problem and data (5 pts)\n",
    "\n",
    "Briefly describe the challenge problem and NLP. Describe the size, dimension, structure, etc., of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf7eef",
   "metadata": {
    "papermill": {
     "duration": 0.002487,
     "end_time": "2025-07-18T23:58:13.624739",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.622252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## II. Exploratory Data Analysis (EDA) ##\n",
    "File: \"train.csv\"\n",
    "- Inspect CSV file dimension (num of rows x num of columns)\n",
    "- Inspect data type and determine if cleaning or data type conversion is required.\n",
    "- Inspect m\n",
    "- Pre-process data frame to add 'train_filepath' for ease access to locate the files\n",
    "- Pre-process data to convert 'label' as string\n",
    "- Drop any rows in the dataset where corresponding .tif file path is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d32df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.632162Z",
     "iopub.status.busy": "2025-07-18T23:58:13.631126Z",
     "iopub.status.idle": "2025-07-18T23:58:13.636033Z",
     "shell.execute_reply": "2025-07-18T23:58:13.635251Z"
    },
    "papermill": {
     "duration": 0.009878,
     "end_time": "2025-07-18T23:58:13.637305",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.627427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34073b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.644970Z",
     "iopub.status.busy": "2025-07-18T23:58:13.644201Z",
     "iopub.status.idle": "2025-07-18T23:58:13.734748Z",
     "shell.execute_reply": "2025-07-18T23:58:13.733842Z"
    },
    "papermill": {
     "duration": 0.095803,
     "end_time": "2025-07-18T23:58:13.736215",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.640412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "sample_submission_df = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11261f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.743416Z",
     "iopub.status.busy": "2025-07-18T23:58:13.743132Z",
     "iopub.status.idle": "2025-07-18T23:58:13.791328Z",
     "shell.execute_reply": "2025-07-18T23:58:13.790374Z"
    },
    "papermill": {
     "duration": 0.053262,
     "end_time": "2025-07-18T23:58:13.792555",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.739293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Development DataSet (train.csv): ==========\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the development set: 7613 rows, 5 columns\n",
      "Max length of Tweet text in Dev. DataSet: 157\n",
      "\n",
      "==========Test DataSet (test.csv): ==========\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the development set: 7613 rows, 5 columns\n",
      "Max length of Tweet text in Test DataSet: 157\n",
      "\n",
      "==========Test DataSet (sample_submission.csv): ==========\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the development set: 3263 rows, 2 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Explore Development DataSet\n",
    "print(f\"\\n{'=' * 10}Development DataSet (train.csv): {'=' * 10}\\n\")\n",
    "display(train_df.head(10))\n",
    "max_text_length_dev = train_df['text'].str.len().max()\n",
    "print(f\"Dimension of the development set: {train_df.shape[0]} rows, {train_df.shape[1]} columns\")\n",
    "print(f\"Max length of Tweet text in Dev. DataSet: {max_text_length_dev}\")\n",
    "\n",
    "# Explore Test DataSet:\n",
    "print(f\"\\n{'=' * 10}Test DataSet (test.csv): {'=' * 10}\\n\")\n",
    "display(test_df.head(10))\n",
    "max_text_length_test = test_df['text'].str.len().max()\n",
    "print(f\"Dimension of the development set: {test_df.shape[0]} rows, {test_df.shape[1]} columns\")\n",
    "print(f\"Max length of Tweet text in Test DataSet: {max_text_length_test}\")\n",
    "\n",
    "\n",
    "# Explore Sapmle Submission file format:\n",
    "print(f\"\\n{'=' * 10}Test DataSet (sample_submission.csv): {'=' * 10}\\n\")\n",
    "display(sample_submission_df.head(5))\n",
    "print(f\"Dimension of the development set: {sample_submission_df.shape[0]} rows, {sample_submission_df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49401e",
   "metadata": {
    "papermill": {
     "duration": 0.003456,
     "end_time": "2025-07-18T23:58:13.799943",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.796487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)\n",
    "\n",
    "Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f14a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.808138Z",
     "iopub.status.busy": "2025-07-18T23:58:13.807824Z",
     "iopub.status.idle": "2025-07-18T23:58:13.812686Z",
     "shell.execute_reply": "2025-07-18T23:58:13.811851Z"
    },
    "papermill": {
     "duration": 0.010648,
     "end_time": "2025-07-18T23:58:13.814076",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.803428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print('2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5d2f4",
   "metadata": {
    "papermill": {
     "duration": 0.003525,
     "end_time": "2025-07-18T23:58:13.821506",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.817981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Model Architecture (25 pts)\n",
    "\n",
    "Describe your model architecture and reasoning for why you believe that specific architecture would be suitable for this problem. \n",
    "\n",
    "Since we did not learn NLP-specific techniques such as word embeddings in the lectures, we recommend looking at Kaggle tutorials, discussion boards, and code examples posted for this challenge.  You can use any resources needed, but make sure you “demonstrate” you understood by including explanations in your own words. Also importantly, please have a reference list at the end of the report.  \n",
    "\n",
    "There are many methods to process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a strategy and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words.\n",
    "\n",
    "Build and train your sequential neural network model (You may use any RNN family neural network, including advanced architectures LSTM, GRU, bidirectional RNN, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f0c42e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.830153Z",
     "iopub.status.busy": "2025-07-18T23:58:13.829856Z",
     "iopub.status.idle": "2025-07-18T23:58:13.834557Z",
     "shell.execute_reply": "2025-07-18T23:58:13.833680Z"
    },
    "papermill": {
     "duration": 0.010617,
     "end_time": "2025-07-18T23:58:13.835954",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.825337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print('3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c781d",
   "metadata": {
    "papermill": {
     "duration": 0.003663,
     "end_time": "2025-07-18T23:58:13.844648",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.840985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. Results and Analysis (35 pts)\n",
    "\n",
    "Run hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.\n",
    "\n",
    "Includes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b857fe4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.853567Z",
     "iopub.status.busy": "2025-07-18T23:58:13.853236Z",
     "iopub.status.idle": "2025-07-18T23:58:13.858163Z",
     "shell.execute_reply": "2025-07-18T23:58:13.857340Z"
    },
    "papermill": {
     "duration": 0.010886,
     "end_time": "2025-07-18T23:58:13.859447",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.848561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print('4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2901a13",
   "metadata": {
    "papermill": {
     "duration": 0.003667,
     "end_time": "2025-07-18T23:58:13.867319",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.863652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. Conclusion (15 pts)\n",
    "\n",
    "Discuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad517303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T23:58:13.876074Z",
     "iopub.status.busy": "2025-07-18T23:58:13.875752Z",
     "iopub.status.idle": "2025-07-18T23:58:13.880549Z",
     "shell.execute_reply": "2025-07-18T23:58:13.879702Z"
    },
    "papermill": {
     "duration": 0.010723,
     "end_time": "2025-07-18T23:58:13.881815",
     "exception": false,
     "start_time": "2025-07-18T23:58:13.871092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print('5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.511601,
   "end_time": "2025-07-18T23:58:14.404662",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-18T23:58:06.893061",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
